import os
import cv2
import pandas as pd
import numpy as np
import torch
import shutil
import torch
import torch.nn as nn
import math
from torch.utils.model_zoo import load_url as load_state_dict_from_url
from torch.backends import cudnn

import os, argparse, random

#import BGRemove_GrabCut
#import BGRemove_DL
import PartAttGen
#from visualize import visualize
import model


def pipeline_span(Or_image_root, mask_dl_ckpt, part_att_ckpt, target_dir):
#if __name__ == '__main__':
    torch.manual_seed(1234)
    torch.cuda.manual_seed(1234)
    torch.cuda.manual_seed_all(1234)
    np.random.seed(1234)
    random.seed(1234)
    torch.backends.cudnn.deterministic = True
    cudnn.benchmark = True
    #os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    #-----parser = argparse.ArgumentParser(description='Train Semantics-guided Part Attention Network (SPAN)', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    #parser.add_argument('--mode', required=True, help='Select training or implementation mode; option: ["train", "implement"]')
    #-----parser.add_argument('--image_root', required=True, help='path to ReId dataset')
    #parser.add_argument('--mask_grabcut_root', default='./BGRemove_GrabCut', help='path to foreground mask generated by GrabCut')
    #parser.add_argument('--mask_dl_root', default='./BGRemove_DL', help='path to foreground mask generated by deep learning network')
    #-----parser.add_argument('--mask_dl_ckpt', default='./BGRemove_DL_ckpt', help='path to store foreground mask generator checkpoint')
    #parser.add_argument('--dataset_csv', default='./dataset.csv', help='Dataset csv file used for training part attention mask generator')
    #parser.add_argument('--part_att_root', default='./PartAttMask', help='path to generated part attention mask')
    #-----parser.add_argument('--part_att_ckpt', default='./PartAttMask_ckpt', help='path to store part attention mask generator checkpoint')
    #-----args = parser.parse_args()
    temp_dataset_root=Or_image_root+'/temp_data'
    try:
        os.mkdir(temp_dataset_root)
    except:
        print('Temp folder is already there')

    f_list=os.listdir(Or_image_root)
    for i in f_list:
        shutil.copytree(Or_image_root+'/'+i , temp_dataset_root+'/'+i)

    image_root=temp_dataset_root
    
    Folder_list=os.listdir(image_root)
    for k in Folder_list:
        if k!='temp_data':
            for (root,dirs,files) in os.walk(image_root+'/'+k, topdown=True):
                if len(dirs) == 0:
                    for i in files:
                        shutil.copy(root+'/'+i, image_root+'/'+k+'/'+i)
                    print(root)
                    shutil.rmtree(root)

            tar_dir_name=target_dir+'/mask_generate_{}'.format(k)
            if not os.path.isdir(tar_dir_name):
                os.mkdir(tar_dir_name)

            part_att_root = tar_dir_name+'/part_attention'


            print("\n### Generate part attention mask ###")
            checkpoint = os.path.join(part_att_ckpt, '10.ckpt')
            PartAttGen.implement(image_root=image_root,
                                mask_root= part_att_root,
                                model= model.PartAtt_Generator().to(device),
                                device= device,
                                checkpoint= checkpoint)


        for (root,dirs,files) in os.walk(image_root+'/mask_generate_'+k+'/part_attention', topdown=True):
            if len(dirs)==0:
                for i in files:
                    shutil.copy(root+'/'+i , image_root+'/mask_generate_'+k+'/part_attention'+'/'+i)
                shutil.rmtree(root)
    
    shutil.rmtree(temp_dataset_root)
    return 0

        


pipeline_span(Or_image_root="/home/fyp3/Desktop/Batch18/Re_ID/Dataset/re_id_weligama", mask_dl_ckpt="/home/fyp3/Desktop/Batch18/Re_ID/Dataset/mask_dl_chckpt/", part_att_ckpt="/home/fyp3/Desktop/Batch18/Re_ID/Dataset/part_attention_ckpt/" , target_dir="/home/fyp3/Desktop/Batch18/Re_ID/" )
    
        
